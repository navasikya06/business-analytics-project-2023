{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c046350",
   "metadata": {},
   "source": [
    "API Key and secret\n",
    "\n",
    "- 5FlPkFBizkmYtyvfql31ie6Ol\n",
    "\n",
    "- E0yhor3Fvy8IRlR8iPRIzU6gQx6tS0fjyhN2jji1JTlDxMVAnZ\n",
    "\n",
    "Access token and secret\n",
    "\n",
    "- 1696734777490173952-CUKOCkUSIC9HG9yIdrSbqF07woehAi\n",
    "\n",
    "- sxpItHpZuHHQO7rug06mOgeV5RX52QoDrknIrlVxFhIdi\n",
    "\n",
    "Bearer token\n",
    "\n",
    "- AAAAAAAAAAAAAAAAAAAAAAVIpwEAAAAAF0iNJBNl6SnNYy6PYsGbTDh4jKs%3DCuBDK7UwJpnKU1u4EWeX8z6bfKX5S08l886iQm9kZRlFeuiRm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41c19763",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "aa67b1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HaThanhChu96723\n"
     ]
    }
   ],
   "source": [
    "consumer_key = \"5FlPkFBizkmYtyvfql31ie6Ol\"\n",
    "consumer_secret = \"E0yhor3Fvy8IRlR8iPRIzU6gQx6tS0fjyhN2jji1JTlDxMVAnZ\"\n",
    "\n",
    "access_token = \"1696734777490173952-CUKOCkUSIC9HG9yIdrSbqF07woehAi\"\n",
    "access_token_secret = \"sxpItHpZuHHQO7rug06mOgeV5RX52QoDrknIrlVxFhIdi\"\n",
    "\n",
    "auth = tweepy.OAuth1UserHandler(\n",
    "    consumer_key, consumer_secret, access_token, access_token_secret\n",
    ")\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "# If the authentication was successful, this should print the\n",
    "# screen name / username of the account\n",
    "print(api.verify_credentials().screen_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05cda79c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (3400467074.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [20]\u001b[1;36m\u001b[0m\n\u001b[1;33m    search_recent_tweets(query = \"twitter data\" has:mentions (has:media OR has:links), *, end_time=None, expansions=None, max_results=10,\u001b[0m\n\u001b[1;37m                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "search_recent_tweets(query = \"twitter data\" has:mentions (has:media OR has:links), *, end_time=None, expansions=None, max_results=10, \n",
    "                                   media_fields=None, next_token=None, place_fields=None, poll_fields=None, \n",
    "                                   since_id=None, sort_order=None, start_time=None, tweet_fields=None, \n",
    "                                   until_id=None, user_fields=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c906f6dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1635437012634181633</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1635439537831698432</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1635455886867980288</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1635458402846375936</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1635461005395337216</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tweetid  sentiment\n",
       "0  1635437012634181633   0.000000\n",
       "1  1635439537831698432   0.142857\n",
       "2  1635455886867980288   0.000000\n",
       "3  1635458402846375936   0.000000\n",
       "4  1635461005395337216   0.000000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('2023_march14_march15.csv', names = ['tweetid', 'sentiment'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ccda1ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1246696937471918080</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1246696937895665664</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1246696938310742016</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1246696939116060673</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1246696939112013825</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tweetid  sentiment\n",
       "0  1246696937471918080        0.0\n",
       "1  1246696937895665664        0.0\n",
       "2  1246696938310742016        0.0\n",
       "3  1246696939116060673        0.5\n",
       "4  1246696939112013825        0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('corona_tweets_18.csv', names = ['tweetid', 'sentiment'])\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42d4fe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe=df1['tweetid']\n",
    "\n",
    "dataframe\n",
    "\n",
    "dataframe.to_csv(\"ready_corona_tweets_18.csv\", index=False, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7ecf9a",
   "metadata": {},
   "source": [
    "https://ieee-dataport.org/open-access/coronavirus-covid-19-tweets-dataset\n",
    "\n",
    "https://github.com/thepanacealab/covid19_twitter/tree/master\n",
    "\n",
    "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7362951/ - SMMT\n",
    "\n",
    "Crisis transformer\n",
    "\n",
    "#corona, coronavirus, #coronavirus, covid, #covid, covid19, #covid19, covid-19, #covid-19, sarscov2, #sarscov2, sars cov2, sars cov 2, covid_19, #covid_19, #ncov, ncov, #ncov2019, ncov2019, 2019-ncov, #2019-ncov, pandemic, #pandemic #2019ncov, 2019ncov, quarantine, #quarantine, flatten the curve, flattening the curve, #flatteningthecurve, #flattenthecurve, hand sanitizer, #handsanitizer, #lockdown, lockdown, social distancing, #socialdistancing, work from home, #workfromhome, working from home, #workingfromhome, ppe, n95, #ppe, #n95, #covidiots, covidiots, herd immunity, #herdimmunity, pneumonia, #pneumonia, chinese virus, #chinesevirus, wuhan virus, #wuhanvirus, kung flu, #kungflu, wearamask, #wearamask, wear a mask, vaccine, vaccines, #vaccine, #vaccines, corona vaccine, corona vaccines, #coronavaccine, #coronavaccines, face shield, #faceshield, face shields, #faceshields, health worker, #healthworker, health workers, #healthworkers, #stayhomestaysafe, #coronaupdate, #frontlineheroes, #coronawarriors, #homeschool, #homeschooling, #hometasking, #masks4all, #wfh, wash ur hands, wash your hands, #washurhands, #washyourhands, #stayathome, #stayhome, #selfisolating, self isolating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0fd2b8b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x9d in position 15: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m access_token_secret\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msxpItHpZuHHQO7rug06mOgeV5RX52QoDrknIrlVxFhIdi\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     10\u001b[0m t \u001b[38;5;241m=\u001b[39m Twarc(consumer_key, consumer_secret, access_token, access_token_secret)\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tweet \u001b[38;5;129;01min\u001b[39;00m t\u001b[38;5;241m.\u001b[39mhydrate(\u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoronatweetids2.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[0;32m     13\u001b[0m     \n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m#print(tweet['text'])\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(tweet[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\lib\\site-packages\\twarc\\client.py:616\u001b[0m, in \u001b[0;36mTwarc.hydrate\u001b[1;34m(self, iterator, trim_user)\u001b[0m\n\u001b[0;32m    613\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://api.twitter.com/1.1/statuses/lookup.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    615\u001b[0m \u001b[38;5;66;03m# lookup 100 tweets at a time\u001b[39;00m\n\u001b[1;32m--> 616\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tweet_id \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[0;32m    617\u001b[0m     tweet_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(tweet_id)\n\u001b[0;32m    618\u001b[0m     tweet_id \u001b[38;5;241m=\u001b[39m tweet_id\u001b[38;5;241m.\u001b[39mstrip()  \u001b[38;5;66;03m# remove new line if present\u001b[39;00m\n",
      "File \u001b[1;32m~\\lib\\encodings\\cp1252.py:23\u001b[0m, in \u001b[0;36mIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcodecs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcharmap_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdecoding_table\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x9d in position 15: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "#$ twarc configure\n",
    "\n",
    "from twarc import Twarc\n",
    "\n",
    "consumer_key=\"5FlPkFBizkmYtyvfql31ie6Ol\"\n",
    "consumer_secret=\"E0yhor3Fvy8IRlR8iPRIzU6gQx6tS0fjyhN2jji1JTlDxMVAnZ\"\n",
    "access_token=\"1696734777490173952-CUKOCkUSIC9HG9yIdrSbqF07woehAi\"\n",
    "access_token_secret=\"sxpItHpZuHHQO7rug06mOgeV5RX52QoDrknIrlVxFhIdi\"\n",
    "\n",
    "t = Twarc(consumer_key, consumer_secret, access_token, access_token_secret)\n",
    "\n",
    "for tweet in t.hydrate(open('coronatweetids2.xlsx')):\n",
    "    \n",
    "    #print(tweet['text'])\n",
    "    print(tweet['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "add356da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1242953451295748096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1242953455418740736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1242953456387649536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1242953461118799872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1242953464080039936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id\n",
       "0  1242953451295748096\n",
       "1  1242953455418740736\n",
       "2  1242953456387649536\n",
       "3  1242953461118799872\n",
       "4  1242953464080039936"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_excel('coronatweetids2.xlsx')\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73f5189a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                         astroworld\n",
       "1                       New York, NY\n",
       "2                   Pewee Valley, KY\n",
       "3               Stuck in the Middle \n",
       "4                  Jammu and Kashmir\n",
       "                     ...            \n",
       "179103               Ilorin, Nigeria\n",
       "179104                       Ontario\n",
       "179105                     🇨🇦 Canada\n",
       "179106                 New York City\n",
       "179107    Aliwal North, South Africa\n",
       "Name: user_location, Length: 179108, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.user_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "04b0f782",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "!pip install twarc #Twarc\n",
    "!pip install tweepy # Tweepy 3.8.0\n",
    "!pip install argparse #Argparse 3.2\n",
    "!pip install xtract #Xtract 0.1 a3\n",
    "!pip install wget #Wget 3.2\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ad59cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [..........................................................................] 4168582 / 4168582"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d1da9421c584bf9becd0d21d325409b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(options=('all', 'am', 'ar', 'bg', 'bn', 'bo', 'ca', 'ckb', 'cs', 'cy', 'da', 'de', 'dv', 'el', 'en', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gzip\n",
    "import shutil\n",
    "import os\n",
    "import wget\n",
    "import csv\n",
    "import linecache\n",
    "from shutil import copyfile\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "dataset_URL = \"https://github.com/thepanacealab/covid19_twitter/blob/master/dailies/2021-01-20/2021-01-20_clean-dataset.tsv.gz?raw=true\" #@param {type:\"string\"}\n",
    "\n",
    "\n",
    "#Downloads the dataset (compressed in a GZ format)\n",
    "#!wget dataset_URL -O clean-dataset.tsv.gz\n",
    "wget.download(dataset_URL, out='clean-dataset.tsv.gz')\n",
    "\n",
    "#Unzips the dataset and gets the TSV dataset\n",
    "with gzip.open('clean-dataset.tsv.gz', 'rb') as f_in:\n",
    "    with open('clean-dataset.tsv', 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "#Deletes the compressed GZ file\n",
    "os.unlink(\"clean-dataset.tsv.gz\")\n",
    "\n",
    "#Gets all possible languages from the dataset\n",
    "df = pd.read_csv('clean-dataset.tsv',sep=\"\\t\")\n",
    "lang_list = df.lang.unique()\n",
    "lang_list= sorted(np.append(lang_list,'all'))\n",
    "lang_picker = widgets.Dropdown(options=lang_list, value=\"all\")\n",
    "lang_picker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fb518ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mShowing first 5 tweets from the filtered dataset\u001b[0m\n",
      "['1351757442653294592\\t2021-01-20\\t05:04:23\\ten\\tNULL\\n', '1351757444033069056\\t2021-01-20\\t05:04:23\\ten\\tNULL\\n', '1351757446860083202\\t2021-01-20\\t05:04:24\\ten\\tNULL\\n', '1351757447619375106\\t2021-01-20\\t05:04:24\\ten\\tNULL\\n', '1351757448219140105\\t2021-01-20\\t05:04:24\\ten\\tNULL\\n']\n"
     ]
    }
   ],
   "source": [
    "filtered_language = lang_picker.value\n",
    "\n",
    "#If no language specified, it will get all records from the dataset\n",
    "if filtered_language == \"\":\n",
    "  copyfile('clean-dataset.tsv', 'clean-dataset-filtered.tsv')\n",
    "\n",
    "#If language specified, it will create another tsv file with the filtered records\n",
    "else:\n",
    "  filtered_tw = list()\n",
    "  current_line = 1\n",
    "  with open(\"clean-dataset.tsv\") as tsvfile:\n",
    "    tsvreader = csv.reader(tsvfile, delimiter=\"\\t\")\n",
    "\n",
    "    if current_line == 1:\n",
    "      filtered_tw.append(linecache.getline(\"clean-dataset.tsv\", current_line))\n",
    "\n",
    "      for line in tsvreader:\n",
    "        if line[3] == filtered_language:\n",
    "          filtered_tw.append(linecache.getline(\"clean-dataset.tsv\", current_line))\n",
    "        current_line += 1\n",
    "\n",
    "  print('\\033[1mShowing first 5 tweets from the filtered dataset\\033[0m')\n",
    "  print(filtered_tw[1:(6 if len(filtered_tw) > 6 else len(filtered_tw))])\n",
    "\n",
    "  with open('clean-dataset-filtered.tsv', 'w') as f_output:\n",
    "      for item in filtered_tw:\n",
    "          f_output.write(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6a8e8117",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "\n",
    "# Authenticate\n",
    "CONSUMER_KEY = \"5FlPkFBizkmYtyvfql31ie6Ol\" #@param {type:\"string\"}\n",
    "CONSUMER_SECRET_KEY = \"E0yhor3Fvy8IRlR8iPRIzU6gQx6tS0fjyhN2jji1JTlDxMVAnZ\" #@param {type:\"string\"}\n",
    "ACCESS_TOKEN_KEY = \"1696734777490173952-CUKOCkUSIC9HG9yIdrSbqF07woehAi\" #@param {type:\"string\"}\n",
    "ACCESS_TOKEN_SECRET_KEY = \"sxpItHpZuHHQO7rug06mOgeV5RX52QoDrknIrlVxFhIdi\" #@param {type:\"string\"}\n",
    "\n",
    "#Creates a JSON Files with the API credentials\n",
    "with open('api_keys.json', 'w') as outfile:\n",
    "    json.dump({\n",
    "    \"consumer_key\":CONSUMER_KEY,\n",
    "    \"consumer_secret\":CONSUMER_SECRET_KEY,\n",
    "    \"access_token\":ACCESS_TOKEN_KEY,\n",
    "    \"access_token_secret\": ACCESS_TOKEN_SECRET_KEY\n",
    "     }, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c6f51114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0% [                                                                                ]    0 / 7205\r",
      "100% [................................................................................] 7205 / 7205"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'get_metadata.py'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "wget.download('https://raw.githubusercontent.com/thepanacealab/SMMT/master/data_acquisition/get_metadata.py', out='get_metadata.py')\n",
    "\n",
    "#clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4414642d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your twitter api credentials are valid.\n",
      "hydrated_tweets\n",
      "tab seperated file, using \\t delimiter\n",
      "total ids: 201374\n",
      "metadata collection complete\n",
      "creating master json file\n",
      "currently getting 0 - 100\n",
      "exception: continuing to zip the file\n",
      "creating ziped master json file\n",
      "creating minimized json master file\n",
      "creating CSV version of minimized json master file\n"
     ]
    }
   ],
   "source": [
    "!python get_metadata.py -i clean-dataset-filtered.tsv -o hydrated_tweets -k api_keys.json\n",
    "\n",
    "#clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "16505960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [................................................................................] 5156 / 5156Requirement already satisfied: emot in c:\\users\\tchu0702\\lib\\site-packages (3.1)\n",
      "Requirement already satisfied: emoji in c:\\users\\tchu0702\\lib\\site-packages (2.8.0)\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "wget.download('https://raw.githubusercontent.com/thepanacealab/SMMT/master/data_preprocessing/parse_json_lite.py', out='parse_json_lite.py')\n",
    "\n",
    "wget.download('https://raw.githubusercontent.com/thepanacealab/SMMT/master/data_preprocessing/fields.py', out='fields.py')\n",
    "\n",
    "\n",
    "!pip install emot --upgrade\n",
    "!pip install emoji --upgrade\n",
    "\n",
    "#clear_output()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5491ac23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "no_samples = \"1000\" #@param {type:\"string\"}\n",
    "list_tweets = None\n",
    "\n",
    "with open(\"hydrated_tweets_short.json\", \"r\") as myfile:\n",
    "    list_tweets = list(myfile)\n",
    "\n",
    "if int(no_samples) > len(list_tweets):\n",
    "    no_samples = len(list_tweets)\n",
    "\n",
    "sample = random.sample(list_tweets, int(no_samples))\n",
    "\n",
    "file = open(\"sample_data.json\", \"w\")\n",
    "for i in sample:\n",
    "  file.write(i)\n",
    "file.close() #This close() is important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "21909ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python parse_json_lite.py sample_data.json p\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7b412fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_description</th>\n",
       "      <th>user_created</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>user_friends</th>\n",
       "      <th>user_favourites</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>source</th>\n",
       "      <th>is_retweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ᏉᎥ☻լꂅϮ</td>\n",
       "      <td>astroworld</td>\n",
       "      <td>wednesday addams as a disney princess keepin i...</td>\n",
       "      <td>2017-05-26 05:46:42</td>\n",
       "      <td>624</td>\n",
       "      <td>950</td>\n",
       "      <td>18775</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-07-25 12:27:21</td>\n",
       "      <td>If I smelled the scent of hand sanitizers toda...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tom Basile 🇺🇸</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Husband, Father, Columnist &amp; Commentator. Auth...</td>\n",
       "      <td>2009-04-16 20:06:23</td>\n",
       "      <td>2253</td>\n",
       "      <td>1677</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-07-25 12:27:17</td>\n",
       "      <td>Hey @Yankees @YankeesPR and @MLB - wouldn't it...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Time4fisticuffs</td>\n",
       "      <td>Pewee Valley, KY</td>\n",
       "      <td>#Christian #Catholic #Conservative #Reagan #Re...</td>\n",
       "      <td>2009-02-28 18:57:41</td>\n",
       "      <td>9275</td>\n",
       "      <td>9525</td>\n",
       "      <td>7254</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-07-25 12:27:14</td>\n",
       "      <td>@diane3443 @wdunlap @realDonaldTrump Trump nev...</td>\n",
       "      <td>['COVID19']</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ethel mertz</td>\n",
       "      <td>Stuck in the Middle</td>\n",
       "      <td>#Browns #Indians #ClevelandProud #[]_[] #Cavs ...</td>\n",
       "      <td>2019-03-07 01:45:06</td>\n",
       "      <td>197</td>\n",
       "      <td>987</td>\n",
       "      <td>1488</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-07-25 12:27:10</td>\n",
       "      <td>@brookbanktv The one gift #COVID19 has give me...</td>\n",
       "      <td>['COVID19']</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DIPR-J&amp;K</td>\n",
       "      <td>Jammu and Kashmir</td>\n",
       "      <td>🖊️Official Twitter handle of Department of Inf...</td>\n",
       "      <td>2017-02-12 06:45:15</td>\n",
       "      <td>101009</td>\n",
       "      <td>168</td>\n",
       "      <td>101</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-07-25 12:27:08</td>\n",
       "      <td>25 July : Media Bulletin on Novel #CoronaVirus...</td>\n",
       "      <td>['CoronaVirusUpdates', 'COVID19']</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_name         user_location  \\\n",
       "0           ᏉᎥ☻լꂅϮ            astroworld   \n",
       "1    Tom Basile 🇺🇸          New York, NY   \n",
       "2  Time4fisticuffs      Pewee Valley, KY   \n",
       "3      ethel mertz  Stuck in the Middle    \n",
       "4         DIPR-J&K     Jammu and Kashmir   \n",
       "\n",
       "                                    user_description         user_created  \\\n",
       "0  wednesday addams as a disney princess keepin i...  2017-05-26 05:46:42   \n",
       "1  Husband, Father, Columnist & Commentator. Auth...  2009-04-16 20:06:23   \n",
       "2  #Christian #Catholic #Conservative #Reagan #Re...  2009-02-28 18:57:41   \n",
       "3  #Browns #Indians #ClevelandProud #[]_[] #Cavs ...  2019-03-07 01:45:06   \n",
       "4  🖊️Official Twitter handle of Department of Inf...  2017-02-12 06:45:15   \n",
       "\n",
       "   user_followers  user_friends  user_favourites  user_verified  \\\n",
       "0             624           950            18775          False   \n",
       "1            2253          1677               24           True   \n",
       "2            9275          9525             7254          False   \n",
       "3             197           987             1488          False   \n",
       "4          101009           168              101          False   \n",
       "\n",
       "                  date                                               text  \\\n",
       "0  2020-07-25 12:27:21  If I smelled the scent of hand sanitizers toda...   \n",
       "1  2020-07-25 12:27:17  Hey @Yankees @YankeesPR and @MLB - wouldn't it...   \n",
       "2  2020-07-25 12:27:14  @diane3443 @wdunlap @realDonaldTrump Trump nev...   \n",
       "3  2020-07-25 12:27:10  @brookbanktv The one gift #COVID19 has give me...   \n",
       "4  2020-07-25 12:27:08  25 July : Media Bulletin on Novel #CoronaVirus...   \n",
       "\n",
       "                            hashtags               source  is_retweet  \n",
       "0                                NaN   Twitter for iPhone       False  \n",
       "1                                NaN  Twitter for Android       False  \n",
       "2                        ['COVID19']  Twitter for Android       False  \n",
       "3                        ['COVID19']   Twitter for iPhone       False  \n",
       "4  ['CoronaVirusUpdates', 'COVID19']  Twitter for Android       False  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df3 = pd.read_csv('covid19_tweets.csv')\n",
    "\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ebdf9a",
   "metadata": {},
   "source": [
    "- Trigrams wordcloud\n",
    "- Most popular hashtags\n",
    "- Count of tweets, graph\n",
    "- Count of tweet by time of day, graph\n",
    "- Sentiment average, graph\n",
    "- Overlay cases\n",
    "- Overlay stringency index\n",
    "\n",
    "https://www.kaggle.com/datasets/gpreda/covid19-tweets\n",
    "\n",
    "https://www.kaggle.com/datasets/arunavakrchakraborty/covid19-twitter-dataset?select=Covid-19+Twitter+Dataset+%28Aug-Sep+2020%29.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
