{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb9f00de",
   "metadata": {},
   "source": [
    "Long Covid - New variant\n",
    "\n",
    "Correlate with number of cases or stringency index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c046350",
   "metadata": {},
   "source": [
    "API Key and secret\n",
    "\n",
    "5FlPkFBizkmYtyvfql31ie6Ol\n",
    "\n",
    "E0yhor3Fvy8IRlR8iPRIzU6gQx6tS0fjyhN2jji1JTlDxMVAnZ\n",
    "\n",
    "Access token and secret\n",
    "\n",
    "1696734777490173952-CUKOCkUSIC9HG9yIdrSbqF07woehAi\n",
    "\n",
    "sxpItHpZuHHQO7rug06mOgeV5RX52QoDrknIrlVxFhIdi\n",
    "\n",
    "Bearer token\n",
    "\n",
    "AAAAAAAAAAAAAAAAAAAAAAVIpwEAAAAAF0iNJBNl6SnNYy6PYsGbTDh4jKs%3DCuBDK7UwJpnKU1u4EWeX8z6bfKX5S08l886iQm9kZRlFeuiRm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41c19763",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa67b1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HaThanhChu96723\n"
     ]
    }
   ],
   "source": [
    "consumer_key = \"5FlPkFBizkmYtyvfql31ie6Ol\"\n",
    "consumer_secret = \"E0yhor3Fvy8IRlR8iPRIzU6gQx6tS0fjyhN2jji1JTlDxMVAnZ\"\n",
    "\n",
    "access_token = \"1696734777490173952-CUKOCkUSIC9HG9yIdrSbqF07woehAi\"\n",
    "access_token_secret = \"sxpItHpZuHHQO7rug06mOgeV5RX52QoDrknIrlVxFhIdi\"\n",
    "\n",
    "auth = tweepy.OAuth1UserHandler(\n",
    "    consumer_key, consumer_secret, access_token, access_token_secret\n",
    ")\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "# If the authentication was successful, this should print the\n",
    "# screen name / username of the account\n",
    "print(api.verify_credentials().screen_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05cda79c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "iterable argument unpacking follows keyword argument unpacking (1389652052.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [9]\u001b[1;36m\u001b[0m\n\u001b[1;33m    search_recent_tweets('', *, end_time=None, expansions=None, max_results=10,\u001b[0m\n\u001b[1;37m                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m iterable argument unpacking follows keyword argument unpacking\n"
     ]
    }
   ],
   "source": [
    "search_recent_tweets(query = \"twitter data\" has:mentions (has:media OR has:links), *, end_time=None, expansions=None, max_results=10, \n",
    "                                   media_fields=None, next_token=None, place_fields=None, poll_fields=None, \n",
    "                                   since_id=None, sort_order=None, start_time=None, tweet_fields=None, \n",
    "                                   until_id=None, user_fields=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d9931d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataframe=pd.read_csv(\"corona_tweets_10.csv\", header=None)\n",
    "\n",
    "dataframe=dataframe[0]\n",
    "\n",
    "dataframe.to_csv(\"ready_corona_tweets_10.csv\", index=False, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7ecf9a",
   "metadata": {},
   "source": [
    "https://ieee-dataport.org/open-access/coronavirus-covid-19-tweets-dataset\n",
    "\n",
    "#corona, coronavirus, #coronavirus, covid, #covid, covid19, #covid19, covid-19, #covid-19, sarscov2, #sarscov2, sars cov2, sars cov 2, covid_19, #covid_19, #ncov, ncov, #ncov2019, ncov2019, 2019-ncov, #2019-ncov, pandemic, #pandemic #2019ncov, 2019ncov, quarantine, #quarantine, flatten the curve, flattening the curve, #flatteningthecurve, #flattenthecurve, hand sanitizer, #handsanitizer, #lockdown, lockdown, social distancing, #socialdistancing, work from home, #workfromhome, working from home, #workingfromhome, ppe, n95, #ppe, #n95, #covidiots, covidiots, herd immunity, #herdimmunity, pneumonia, #pneumonia, chinese virus, #chinesevirus, wuhan virus, #wuhanvirus, kung flu, #kungflu, wearamask, #wearamask, wear a mask, vaccine, vaccines, #vaccine, #vaccines, corona vaccine, corona vaccines, #coronavaccine, #coronavaccines, face shield, #faceshield, face shields, #faceshields, health worker, #healthworker, health workers, #healthworkers, #stayhomestaysafe, #coronaupdate, #frontlineheroes, #coronawarriors, #homeschool, #homeschooling, #hometasking, #masks4all, #wfh, wash ur hands, wash your hands, #washurhands, #washyourhands, #stayathome, #stayhome, #selfisolating, self isolating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd2b8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "$ twarc configure\n",
    "\n",
    "from twarc import Twarc\n",
    "\n",
    "consumer_key=\"\"\n",
    "consumer_secret=\"\"\n",
    "access_token=\"\"\n",
    "access_token_secret=\"\"\n",
    "\n",
    "t = Twarc(consumer_key, consumer_secret, access_token, access_token_secret)\n",
    "\n",
    "for tweet in t.hydrate(open('tweet_ids.csv')):\n",
    "    \n",
    "    print(tweet['text'])\n",
    "    print(tweet['id'])\n",
    "    \n",
    "    if tweet['place']:\n",
    "        print(tweet['place']['country'])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7db15d3",
   "metadata": {},
   "source": [
    "https://github.com/thepanacealab/covid19_twitter/tree/master\n",
    "\n",
    "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7362951/\n",
    "\n",
    "Crisis Transformer\n",
    "\n",
    "Hydrate - can't do\n",
    "Process\n",
    "\n",
    "- Visualize sentiment based on data available, looking at articles\n",
    "- Predict case\n",
    "- How a social media monitoring dashboard would look like for COVID\n",
    "- How it would look like for a crisis management\n",
    "\n",
    "Ask chatgpt, find previous code to copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0492fbf5",
   "metadata": {},
   "source": [
    "##### Find the most common trigrams in the text columns of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53082dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from nltk import ngrams, word_tokenize\n",
    "import string\n",
    "\n",
    "# Tokenize and clean the text\n",
    "def tokenize(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    return word_tokenize(text)\n",
    "\n",
    "# Extract trigrams from the tokenized text\n",
    "def extract_trigrams(tokens):\n",
    "    return list(ngrams(tokens, 3))\n",
    "\n",
    "# Tokenize and get trigrams for each tweet\n",
    "all_trigrams = []\n",
    "for tweet in df['text']:\n",
    "    tokens = tokenize(tweet)\n",
    "    trigrams = extract_trigrams(tokens)\n",
    "    all_trigrams.extend(trigrams)\n",
    "\n",
    "# Find most common trigrams\n",
    "common_trigrams = Counter(all_trigrams).most_common(10)\n",
    "common_trigrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80e70f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing using an alternative method (without NLTK's tokenizer)\n",
    "def simple_tokenize(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation and tokenize\n",
    "    tokens = text.translate(str.maketrans('', '', string.punctuation)).split()\n",
    "    return tokens\n",
    "\n",
    "# Tokenize and get trigrams for each tweet using the simple tokenizer\n",
    "all_trigrams = []\n",
    "for tweet in df['text']:\n",
    "    tokens = simple_tokenize(tweet)\n",
    "    trigrams = extract_trigrams(tokens)\n",
    "    all_trigrams.extend(trigrams)\n",
    "\n",
    "# Find most common trigrams\n",
    "common_trigrams = Counter(all_trigrams).most_common(10)\n",
    "common_trigrams\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bb8fac",
   "metadata": {},
   "source": [
    "#### Calculate Sentiment scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bd6b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ea8227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"path_to_your_file/covid19_tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f75b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize VADER sentiment intensity analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Calculate sentiment scores\n",
    "df['sentiment_score'] = df['text'].apply(lambda tweet: sia.polarity_scores(tweet)['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf4c9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated dataframe to a new CSV file if needed\n",
    "df.to_csv(\"path_to_save_file/updated_tweets.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f76d962",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(df['sentiment_score'], bins=50, facecolor='blue', alpha=0.7)\n",
    "plt.title('Sentiment Score Distribution')\n",
    "plt.xlabel('Sentiment Score')\n",
    "plt.ylabel('Number of Tweets')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50d8add",
   "metadata": {},
   "source": [
    "#### Plot the number of tweets by date and by time of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbca1660",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"path_to_your_file/covid19_tweets.csv\")\n",
    "\n",
    "# Convert 'date' column to datetime format\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Plot number of tweets by date\n",
    "df.groupby(df['date'].dt.date).size().plot(kind='line', figsize=(12, 6))\n",
    "plt.title('Number of Tweets by Date')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Tweets')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot number of tweets by time of day\n",
    "df.groupby(df['date'].dt.hour).size().plot(kind='bar', figsize=(12, 6))\n",
    "plt.title('Number of Tweets by Time of Day')\n",
    "plt.xlabel('Hour of Day (24-hour format)')\n",
    "plt.ylabel('Number of Tweets')\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de86598",
   "metadata": {},
   "source": [
    "#### Plot the overlay number of tweets with number of new cases, based on the 2 datasets: covid19_tweets.csv and owid-covid-data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad33821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the datasets\n",
    "df_tweets = pd.read_csv(\"path_to_your_file/covid19_tweets.csv\")\n",
    "df_covid = pd.read_csv(\"path_to_your_file/owid-covid-data.csv\")\n",
    "\n",
    "# Convert 'date' columns to datetime format\n",
    "df_tweets['date'] = pd.to_datetime(df_tweets['date'])\n",
    "df_covid['date'] = pd.to_datetime(df_covid['date'])\n",
    "\n",
    "# Aggregate number of tweets by date\n",
    "tweets_by_date = df_tweets.groupby(df_tweets['date'].dt.date).size()\n",
    "\n",
    "# Aggregate number of new cases by date (summing across all countries)\n",
    "cases_by_date = df_covid.groupby(df_covid['date'].dt.date)['new_cases'].sum()\n",
    "\n",
    "# Plotting\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plot number of tweets on the left y-axis\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Number of Tweets', color='tab:blue')\n",
    "ax1.plot(tweets_by_date.index, tweets_by_date.values, color='tab:blue', label='Tweets')\n",
    "ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "# Create a second y-axis for the number of new cases\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Number of New Cases', color='tab:red')\n",
    "ax2.plot(cases_by_date.index, cases_by_date.values, color='tab:red', label='New Cases')\n",
    "ax2.tick_params(axis='y', labelcolor='tab:red')\n",
    "\n",
    "# Show the plot\n",
    "plt.title('Number of Tweets vs. Number of New Cases by Date')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad0cc8e",
   "metadata": {},
   "source": [
    "#### plot the overlay number of tweets with stringtency index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6582b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the datasets\n",
    "df_tweets = pd.read_csv(\"path_to_your_file/covid19_tweets.csv\")\n",
    "df_covid = pd.read_csv(\"path_to_your_file/owid-covid-data.csv\")\n",
    "\n",
    "# Convert 'date' columns to datetime format\n",
    "df_tweets['date'] = pd.to_datetime(df_tweets['date'])\n",
    "df_covid['date'] = pd.to_datetime(df_covid['date'])\n",
    "\n",
    "# Aggregate number of tweets by date\n",
    "tweets_by_date = df_tweets.groupby(df_tweets['date'].dt.date).size()\n",
    "\n",
    "# Aggregate stringency index by date (averaging across all countries)\n",
    "stringency_by_date = df_covid.groupby(df_covid['date'].dt.date)['stringency_index'].mean()\n",
    "\n",
    "# Plotting\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plot number of tweets on the left y-axis\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Number of Tweets', color='tab:blue')\n",
    "ax1.plot(tweets_by_date.index, tweets_by_date.values, color='tab:blue', label='Tweets')\n",
    "ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "# Create a second y-axis for the stringency index\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Stringency Index', color='tab:red')\n",
    "ax2.plot(stringency_by_date.index, stringency_by_date.values, color='tab:red', label='Stringency Index')\n",
    "ax2.tick_params(axis='y', labelcolor='tab:red')\n",
    "\n",
    "# Show the plot\n",
    "plt.title('Number of Tweets vs. Stringency Index by Date')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96df148",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
